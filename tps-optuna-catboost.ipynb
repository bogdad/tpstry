{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "169f4c2e-f254-4597-85b5-82ae3520642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Familiar imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For ordinal encoding categorical variables, splitting data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "# For training random forest model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, roc_auc_score\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from tqdm import tqdm\n",
    "import optuna\n",
    "\n",
    "from lightgbm import LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1cbd7c5-085a-4e15-8dd8-f54bc219523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>f9</th>\n",
       "      <th>...</th>\n",
       "      <th>f91</th>\n",
       "      <th>f92</th>\n",
       "      <th>f93</th>\n",
       "      <th>f94</th>\n",
       "      <th>f95</th>\n",
       "      <th>f96</th>\n",
       "      <th>f97</th>\n",
       "      <th>f98</th>\n",
       "      <th>f99</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.106643</td>\n",
       "      <td>3.59437</td>\n",
       "      <td>132.8040</td>\n",
       "      <td>3.18428</td>\n",
       "      <td>0.081971</td>\n",
       "      <td>1.18859</td>\n",
       "      <td>3.73238</td>\n",
       "      <td>2.266270</td>\n",
       "      <td>2.09959</td>\n",
       "      <td>0.012330</td>\n",
       "      <td>...</td>\n",
       "      <td>1.09862</td>\n",
       "      <td>0.013331</td>\n",
       "      <td>-0.011715</td>\n",
       "      <td>0.052759</td>\n",
       "      <td>0.065400</td>\n",
       "      <td>4.211250</td>\n",
       "      <td>1.97877</td>\n",
       "      <td>0.085974</td>\n",
       "      <td>0.240496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.125021</td>\n",
       "      <td>1.67336</td>\n",
       "      <td>76.5336</td>\n",
       "      <td>3.37825</td>\n",
       "      <td>0.099400</td>\n",
       "      <td>5.09366</td>\n",
       "      <td>1.27562</td>\n",
       "      <td>-0.471318</td>\n",
       "      <td>4.54594</td>\n",
       "      <td>0.037706</td>\n",
       "      <td>...</td>\n",
       "      <td>3.46017</td>\n",
       "      <td>0.017054</td>\n",
       "      <td>0.124863</td>\n",
       "      <td>0.154064</td>\n",
       "      <td>0.606848</td>\n",
       "      <td>-0.267928</td>\n",
       "      <td>2.57786</td>\n",
       "      <td>-0.020877</td>\n",
       "      <td>0.024719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.036330</td>\n",
       "      <td>1.49747</td>\n",
       "      <td>233.5460</td>\n",
       "      <td>2.19435</td>\n",
       "      <td>0.026914</td>\n",
       "      <td>3.12694</td>\n",
       "      <td>5.05687</td>\n",
       "      <td>3.849460</td>\n",
       "      <td>1.80187</td>\n",
       "      <td>0.056995</td>\n",
       "      <td>...</td>\n",
       "      <td>4.88300</td>\n",
       "      <td>0.085222</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>0.116092</td>\n",
       "      <td>-0.001688</td>\n",
       "      <td>-0.520069</td>\n",
       "      <td>2.14112</td>\n",
       "      <td>0.124464</td>\n",
       "      <td>0.148209</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.014077</td>\n",
       "      <td>0.24600</td>\n",
       "      <td>779.9670</td>\n",
       "      <td>1.89064</td>\n",
       "      <td>0.006948</td>\n",
       "      <td>1.53112</td>\n",
       "      <td>2.69800</td>\n",
       "      <td>4.517330</td>\n",
       "      <td>4.50332</td>\n",
       "      <td>0.123494</td>\n",
       "      <td>...</td>\n",
       "      <td>3.47439</td>\n",
       "      <td>-0.017103</td>\n",
       "      <td>-0.008100</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.041193</td>\n",
       "      <td>0.511657</td>\n",
       "      <td>1.96860</td>\n",
       "      <td>0.040017</td>\n",
       "      <td>0.044873</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.003259</td>\n",
       "      <td>3.71542</td>\n",
       "      <td>156.1280</td>\n",
       "      <td>2.14772</td>\n",
       "      <td>0.018284</td>\n",
       "      <td>2.09859</td>\n",
       "      <td>4.15492</td>\n",
       "      <td>-0.038236</td>\n",
       "      <td>3.37145</td>\n",
       "      <td>0.034166</td>\n",
       "      <td>...</td>\n",
       "      <td>1.91059</td>\n",
       "      <td>-0.042943</td>\n",
       "      <td>0.105616</td>\n",
       "      <td>0.125072</td>\n",
       "      <td>0.037509</td>\n",
       "      <td>1.043790</td>\n",
       "      <td>1.07481</td>\n",
       "      <td>-0.012819</td>\n",
       "      <td>0.072798</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          f0       f1        f2       f3        f4       f5       f6  \\\n",
       "id                                                                     \n",
       "0   0.106643  3.59437  132.8040  3.18428  0.081971  1.18859  3.73238   \n",
       "1   0.125021  1.67336   76.5336  3.37825  0.099400  5.09366  1.27562   \n",
       "2   0.036330  1.49747  233.5460  2.19435  0.026914  3.12694  5.05687   \n",
       "3  -0.014077  0.24600  779.9670  1.89064  0.006948  1.53112  2.69800   \n",
       "4  -0.003259  3.71542  156.1280  2.14772  0.018284  2.09859  4.15492   \n",
       "\n",
       "          f7       f8        f9  ...      f91       f92       f93       f94  \\\n",
       "id                               ...                                          \n",
       "0   2.266270  2.09959  0.012330  ...  1.09862  0.013331 -0.011715  0.052759   \n",
       "1  -0.471318  4.54594  0.037706  ...  3.46017  0.017054  0.124863  0.154064   \n",
       "2   3.849460  1.80187  0.056995  ...  4.88300  0.085222  0.032396  0.116092   \n",
       "3   4.517330  4.50332  0.123494  ...  3.47439 -0.017103 -0.008100  0.062013   \n",
       "4  -0.038236  3.37145  0.034166  ...  1.91059 -0.042943  0.105616  0.125072   \n",
       "\n",
       "         f95       f96      f97       f98       f99  target  \n",
       "id                                                           \n",
       "0   0.065400  4.211250  1.97877  0.085974  0.240496       0  \n",
       "1   0.606848 -0.267928  2.57786 -0.020877  0.024719       0  \n",
       "2  -0.001688 -0.520069  2.14112  0.124464  0.148209       0  \n",
       "3   0.041193  0.511657  1.96860  0.040017  0.044873       0  \n",
       "4   0.037509  1.043790  1.07481 -0.012819  0.072798       1  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the training data\n",
    "train = pd.read_csv(\"../input/tabular-playground-series-nov-2021/train.csv\", index_col=0)\n",
    "test = pd.read_csv(\"../input/tabular-playground-series-nov-2021/test.csv\", index_col=0)\n",
    "\n",
    "# Preview the data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20607adb-7b42-493a-9852-acb6d60a1f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 100)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = train['target']\n",
    "features = train.drop(['target'], axis=1)\n",
    "\n",
    "X = features.copy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ea18e4-d838-49ca-a2c5-4ee9d4fc68a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(**kvargs):\n",
    "    typ = kvargs.pop('typ')\n",
    "    if typ == 'xgboost':\n",
    "        model = XGBRegressor(**kvargs, n_jobs=3, tree_method='gpu_hist', gpu_id=0, eval_metric=\"auc\")\n",
    "    elif typ == 'lgbm':\n",
    "        model = LGBMRegressor(**kvargs, n_jobs=3, device='gpu', metric = \"auc\")\n",
    "    else:\n",
    "        model = CatBoostRegressor(**kvargs, task_type=\"GPU\", loss_function=\"RMSE\")\n",
    "    \n",
    "    #pipeline = Pipeline(steps=[\n",
    "    #    ('preprocessor', preprocessor),\n",
    "    #    ('model', model)\n",
    "    #])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bac018f-d709-4f0a-b925-8c6efc1bb893",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, typ):\n",
    "    #n_estimators = trial.suggest_int(\"n_estimators\", 500, 5000)\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.03, 0.5)\n",
    "    stopping_rounds = 400\n",
    "    params={'typ':typ}\n",
    "    if typ == 'xgboost':\n",
    "        params['booster']='gbtree'\n",
    "        params['n_estimators'] = trial.suggest_int(\"n_estimators\", 5000, 20000)\n",
    "        params['gamma'] = trial.suggest_float('gamma', 0, 100)\n",
    "        params['max_depth'] = trial.suggest_int('max_depth', 1, 10)\n",
    "        params['min_child_weight']=trial.suggest_float('min_child_weight', 0, 10)\n",
    "        params['subsample']=trial.suggest_float('subsample', 0.1, 1)\n",
    "        params['lambda']=trial.suggest_float('lambda', 1, 5)\n",
    "        params['alpha']=trial.suggest_float('alpha', 0, 10)\n",
    "    elif typ=='lgbm':\n",
    "        params['n_estimators'] = trial.suggest_int(\"n_estimators\", 500, 5000)\n",
    "        params['max_depth']=trial.suggest_int('max_depth', 2, 10)\n",
    "        params['num_leaves']=trial.suggest_int('num_leaves', 2, 100)\n",
    "        params['reg_alpha']=trial.suggest_float('reg_alpha', 0, 10)\n",
    "        params['reg_lambda']=trial.suggest_float('reg_lambda', 0, 10)\n",
    "        params['min_data_in_leaf']=trial.suggest_int('min_data_in_leaf', 50, 1000)\n",
    "    else:\n",
    "        params['iterations'] = trial.suggest_int(\"iterations\", 500, 10000)\n",
    "        params['depth'] = trial.suggest_int(\"depth\", 3, 15)\n",
    "        params['l2_leaf_reg']=trial.suggest_float('l2_leaf_reg', 0.01, 100)\n",
    "        params['bagging_temperature']=trial.suggest_float('bagging_temperature', 0, 10)\n",
    "    #score = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    val_pred = np.zeros(len(y))\n",
    "\n",
    "    mse = []\n",
    "    spl = 10\n",
    "    kf = KFold(n_splits=spl, shuffle=True)\n",
    "    for trn_idx, val_idx in tqdm(kf.split(X,y)):\n",
    "        x_train_idx = X.iloc[trn_idx]\n",
    "        y_train_idx = y.iloc[trn_idx]\n",
    "        x_valid_idx = X.iloc[val_idx]\n",
    "        y_valid_idx = y.iloc[val_idx]\n",
    "\n",
    "        model = create_pipeline(learning_rate=learning_rate, **params)\n",
    "        verbose = -1\n",
    "        if typ == 'xgboost':\n",
    "            verbose = False\n",
    "        if typ == 'catboost':\n",
    "            verbose = 0\n",
    "        model.fit(x_train_idx, y_train_idx, early_stopping_rounds = stopping_rounds, eval_set=[(x_valid_idx, y_valid_idx)], verbose = verbose)\n",
    "        mse.append(roc_auc_score(y_valid_idx, model.predict(x_valid_idx)))\n",
    "    \n",
    "    accuracy = sum(mse)/spl\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "185afe75-106d-4b7b-ae5c-1ffaca46f49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-11-03 14:34:40,775]\u001b[0m A new study created in RDB with name: tps-nov2-catboost\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study_name = 'tps-nov2-catboost'  # Unique identifier of the study.\n",
    "study = optuna.create_study(study_name=study_name, storage='sqlite:///'+study_name+'.db', direction=\"maximize\", load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfae3f0f-b390-44fd-96ac-154f4b3cd1d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Record does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23784/2634521730.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36mbest_trial\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     95\u001b[0m             )\n\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 97\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_study_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\optuna\\storages\\_cached_storage.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[1;34m(self, study_id)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_best_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mFrozenTrial\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_best_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_trial_param\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrial_id\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\optuna\\storages\\_rdb\\storage.py\u001b[0m in \u001b[0;36mget_best_trial\u001b[1;34m(self, study_id)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1120\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdirection\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mStudyDirection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMAXIMIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                 \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_max_value_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m                 \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_min_value_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\lib\\site-packages\\optuna\\storages\\_rdb\\models.py\u001b[0m in \u001b[0;36mfind_max_value_trial\u001b[1;34m(cls, study_id, objective, session)\u001b[0m\n\u001b[0;32m    205\u001b[0m         )\n\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtrial\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNOT_FOUND_MSG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Record does not exist."
     ]
    }
   ],
   "source": [
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "018eda20-94da-4242-9f52-74aae66d7d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [01:17,  7.76s/it]\n",
      "\u001b[32m[I 2021-11-03 14:36:18,630]\u001b[0m Trial 0 finished with value: 0.7366972329136144 and parameters: {'learning_rate': 0.2804374089423294, 'iterations': 911, 'depth': 10, 'l2_leaf_reg': 1.3615213224086675, 'bagging_temperature': 2.6382729132406944}. Best is trial 0 with value: 0.7366972329136144.\u001b[0m\n",
      "10it [05:21, 32.10s/it]\n",
      "\u001b[32m[I 2021-11-03 14:41:39,715]\u001b[0m Trial 1 finished with value: 0.7472400288714074 and parameters: {'learning_rate': 0.06325556363732907, 'iterations': 9521, 'depth': 3, 'l2_leaf_reg': 57.91357941609552, 'bagging_temperature': 9.591178298981774}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [07:43, 46.36s/it]\n",
      "\u001b[32m[I 2021-11-03 14:49:23,359]\u001b[0m Trial 2 finished with value: 0.7226780103579472 and parameters: {'learning_rate': 0.12319250141804054, 'iterations': 865, 'depth': 13, 'l2_leaf_reg': 41.641907665610695, 'bagging_temperature': 8.581173647123963}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [03:19, 19.96s/it]\n",
      "\u001b[32m[I 2021-11-03 14:52:43,097]\u001b[0m Trial 3 finished with value: 0.7405188370945524 and parameters: {'learning_rate': 0.12783232827159718, 'iterations': 9302, 'depth': 8, 'l2_leaf_reg': 66.62037297906201, 'bagging_temperature': 8.86448166571544}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [01:34,  9.49s/it]\n",
      "\u001b[32m[I 2021-11-03 14:54:18,083]\u001b[0m Trial 4 finished with value: 0.7341241828315439 and parameters: {'learning_rate': 0.22680750075309486, 'iterations': 912, 'depth': 10, 'l2_leaf_reg': 7.58653838436533, 'bagging_temperature': 5.7984092843899955}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [02:32, 15.22s/it]\n",
      "\u001b[32m[I 2021-11-03 14:56:50,398]\u001b[0m Trial 5 finished with value: 0.7437086978286425 and parameters: {'learning_rate': 0.12206196610136147, 'iterations': 1024, 'depth': 10, 'l2_leaf_reg': 47.80326600034706, 'bagging_temperature': 3.1727362821872984}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [02:15, 13.58s/it]\n",
      "\u001b[32m[I 2021-11-03 14:59:06,269]\u001b[0m Trial 6 finished with value: 0.7456798241924792 and parameters: {'learning_rate': 0.03241857238380827, 'iterations': 3921, 'depth': 3, 'l2_leaf_reg': 9.48004047960896, 'bagging_temperature': 6.240707742326239}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [01:33,  9.38s/it]\n",
      "\u001b[32m[I 2021-11-03 15:00:40,135]\u001b[0m Trial 7 finished with value: 0.7450927345980582 and parameters: {'learning_rate': 0.16535023969745866, 'iterations': 3623, 'depth': 7, 'l2_leaf_reg': 26.400377970012887, 'bagging_temperature': 1.9467102848893325}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [04:23, 26.38s/it]\n",
      "\u001b[32m[I 2021-11-03 15:05:04,018]\u001b[0m Trial 8 finished with value: 0.7255094772071669 and parameters: {'learning_rate': 0.4539925630091418, 'iterations': 2788, 'depth': 13, 'l2_leaf_reg': 18.552555871245612, 'bagging_temperature': 2.227802815200585}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [02:07, 12.72s/it]\n",
      "\u001b[32m[I 2021-11-03 15:07:11,319]\u001b[0m Trial 9 finished with value: 0.7437756337492815 and parameters: {'learning_rate': 0.35636323744607035, 'iterations': 4297, 'depth': 3, 'l2_leaf_reg': 50.3175098032871, 'bagging_temperature': 9.92659049204151}. Best is trial 1 with value: 0.7472400288714074.\u001b[0m\n",
      "10it [07:48, 46.83s/it]\n",
      "\u001b[32m[I 2021-11-03 15:14:59,713]\u001b[0m Trial 10 finished with value: 0.7482967771807189 and parameters: {'learning_rate': 0.04476037313383397, 'iterations': 9955, 'depth': 5, 'l2_leaf_reg': 85.61538016813577, 'bagging_temperature': 7.246464508030584}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [07:42, 46.25s/it]\n",
      "\u001b[32m[I 2021-11-03 15:22:42,275]\u001b[0m Trial 11 finished with value: 0.7480850663923043 and parameters: {'learning_rate': 0.038299447410708516, 'iterations': 9814, 'depth': 5, 'l2_leaf_reg': 96.68942495495541, 'bagging_temperature': 7.392896467055616}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [07:11, 43.15s/it]\n",
      "\u001b[32m[I 2021-11-03 15:29:53,912]\u001b[0m Trial 12 finished with value: 0.7475822888446557 and parameters: {'learning_rate': 0.03586766475025807, 'iterations': 7638, 'depth': 6, 'l2_leaf_reg': 97.73909801410736, 'bagging_temperature': 7.64204168926298}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [01:42, 10.25s/it]\n",
      "\u001b[32m[I 2021-11-03 15:31:36,548]\u001b[0m Trial 13 finished with value: 0.7458634445599991 and parameters: {'learning_rate': 0.21458256328446498, 'iterations': 7148, 'depth': 5, 'l2_leaf_reg': 99.62990697657395, 'bagging_temperature': 4.294175180116518}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [01:25,  8.57s/it]\n",
      "\u001b[32m[I 2021-11-03 15:33:02,361]\u001b[0m Trial 14 finished with value: 0.7426413276295009 and parameters: {'learning_rate': 0.33404339719982057, 'iterations': 7674, 'depth': 5, 'l2_leaf_reg': 79.31536290539316, 'bagging_temperature': 7.080454760606331}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:39, 27.96s/it]\n",
      "\u001b[32m[I 2021-11-03 15:37:42,026]\u001b[0m Trial 15 finished with value: 0.7474793101647987 and parameters: {'learning_rate': 0.08420350828413889, 'iterations': 9921, 'depth': 5, 'l2_leaf_reg': 81.97976051505299, 'bagging_temperature': 4.617472834875127}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [02:10, 13.01s/it]\n",
      "\u001b[32m[I 2021-11-03 15:39:52,226]\u001b[0m Trial 16 finished with value: 0.7400867840109964 and parameters: {'learning_rate': 0.18433877604781035, 'iterations': 5786, 'depth': 8, 'l2_leaf_reg': 82.68949484868591, 'bagging_temperature': 7.7027779265358145}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [00:39,  3.94s/it]\n",
      "\u001b[32m[I 2021-11-03 15:40:31,756]\u001b[0m Trial 17 finished with value: 0.7415860994998186 and parameters: {'learning_rate': 0.45651794832942166, 'iterations': 8676, 'depth': 6, 'l2_leaf_reg': 69.84790822425397, 'bagging_temperature': 0.6875034242343476}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [59:28, 356.85s/it]\n",
      "\u001b[32m[I 2021-11-03 16:40:00,341]\u001b[0m Trial 18 finished with value: 0.7283900508847625 and parameters: {'learning_rate': 0.08350863476685952, 'iterations': 6260, 'depth': 15, 'l2_leaf_reg': 87.35235596577911, 'bagging_temperature': 6.191019610914936}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [01:40, 10.02s/it]\n",
      "\u001b[32m[I 2021-11-03 16:41:40,594]\u001b[0m Trial 19 finished with value: 0.7452918465900573 and parameters: {'learning_rate': 0.26161408471660874, 'iterations': 8550, 'depth': 4, 'l2_leaf_reg': 91.08079167731925, 'bagging_temperature': 5.3170569634554985}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [00:55,  5.60s/it]\n",
      "\u001b[32m[I 2021-11-03 16:42:36,652]\u001b[0m Trial 20 finished with value: 0.7317165305175224 and parameters: {'learning_rate': 0.49932869239432354, 'iterations': 6791, 'depth': 8, 'l2_leaf_reg': 71.75724853440045, 'bagging_temperature': 6.8507999468900715}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [07:47, 46.79s/it]\n",
      "\u001b[32m[I 2021-11-03 16:50:24,602]\u001b[0m Trial 21 finished with value: 0.7477116475668815 and parameters: {'learning_rate': 0.03984702070066479, 'iterations': 8088, 'depth': 6, 'l2_leaf_reg': 96.25156239742641, 'bagging_temperature': 7.901089641797278}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:25, 38.57s/it]\n",
      "\u001b[32m[I 2021-11-03 16:56:50,359]\u001b[0m Trial 22 finished with value: 0.7463824366498498 and parameters: {'learning_rate': 0.08213913434018731, 'iterations': 8582, 'depth': 6, 'l2_leaf_reg': 94.93898416775433, 'bagging_temperature': 8.50768347495428}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:44, 40.43s/it]\n",
      "\u001b[32m[I 2021-11-03 17:03:34,775]\u001b[0m Trial 23 finished with value: 0.7476142998752449 and parameters: {'learning_rate': 0.0333568619520775, 'iterations': 9974, 'depth': 4, 'l2_leaf_reg': 76.99862837556309, 'bagging_temperature': 7.893590243258531}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [03:01, 18.17s/it]\n",
      "\u001b[32m[I 2021-11-03 17:06:36,613]\u001b[0m Trial 24 finished with value: 0.7445339853667361 and parameters: {'learning_rate': 0.1457898637743825, 'iterations': 9003, 'depth': 7, 'l2_leaf_reg': 89.54929603241968, 'bagging_temperature': 6.818897559509374}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:23, 32.33s/it]\n",
      "\u001b[32m[I 2021-11-03 17:12:00,032]\u001b[0m Trial 25 finished with value: 0.7474504010639718 and parameters: {'learning_rate': 0.09743894760440708, 'iterations': 8158, 'depth': 4, 'l2_leaf_reg': 62.33134750635477, 'bagging_temperature': 8.871453196147488}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:06, 36.65s/it]\n",
      "\u001b[32m[I 2021-11-03 17:18:06,661]\u001b[0m Trial 26 finished with value: 0.747701514786816 and parameters: {'learning_rate': 0.06550026125690447, 'iterations': 8068, 'depth': 7, 'l2_leaf_reg': 99.97965546269822, 'bagging_temperature': 3.9205529633566454}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [02:06, 12.62s/it]\n",
      "\u001b[32m[I 2021-11-03 17:20:12,928]\u001b[0m Trial 27 finished with value: 0.736575097976762 and parameters: {'learning_rate': 0.18958553648824877, 'iterations': 9448, 'depth': 9, 'l2_leaf_reg': 87.59077180440984, 'bagging_temperature': 7.937627733116505}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [03:44, 22.42s/it]\n",
      "\u001b[32m[I 2021-11-03 17:23:57,229]\u001b[0m Trial 28 finished with value: 0.7473036296074921 and parameters: {'learning_rate': 0.1053884979768819, 'iterations': 6593, 'depth': 5, 'l2_leaf_reg': 74.14900260099222, 'bagging_temperature': 5.607309464114149}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [03:20, 20.09s/it]\n",
      "\u001b[32m[I 2021-11-03 17:27:18,250]\u001b[0m Trial 29 finished with value: 0.7170401110401798 and parameters: {'learning_rate': 0.2858175855626642, 'iterations': 7456, 'depth': 12, 'l2_leaf_reg': 91.86826185903911, 'bagging_temperature': 9.304248090633429}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [03:12, 19.24s/it]\n",
      "\u001b[32m[I 2021-11-03 17:30:30,775]\u001b[0m Trial 30 finished with value: 0.7451058225496128 and parameters: {'learning_rate': 0.14825701317164072, 'iterations': 5641, 'depth': 6, 'l2_leaf_reg': 83.42757772478046, 'bagging_temperature': 7.125852476376703}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [07:13, 43.32s/it]\n",
      "\u001b[32m[I 2021-11-03 17:37:44,059]\u001b[0m Trial 31 finished with value: 0.7479619748783126 and parameters: {'learning_rate': 0.054998875188943766, 'iterations': 8159, 'depth': 7, 'l2_leaf_reg': 98.89872161679332, 'bagging_temperature': 3.7371943794489493}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:10, 37.01s/it]\n",
      "\u001b[32m[I 2021-11-03 17:43:54,232]\u001b[0m Trial 32 finished with value: 0.7477832119344705 and parameters: {'learning_rate': 0.060160531126292965, 'iterations': 9157, 'depth': 7, 'l2_leaf_reg': 93.6568887765389, 'bagging_temperature': 3.2161147839147466}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:27, 32.74s/it]\n",
      "\u001b[32m[I 2021-11-03 17:49:21,743]\u001b[0m Trial 33 finished with value: 0.7466929631737671 and parameters: {'learning_rate': 0.06754389144879296, 'iterations': 9183, 'depth': 9, 'l2_leaf_reg': 86.62588083462079, 'bagging_temperature': 3.1558317088583183}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:12, 31.22s/it]\n",
      "\u001b[32m[I 2021-11-03 17:54:33,998]\u001b[0m Trial 34 finished with value: 0.747379296786145 and parameters: {'learning_rate': 0.05936006979257444, 'iterations': 9970, 'depth': 7, 'l2_leaf_reg': 92.38976116544306, 'bagging_temperature': 1.5264349226976441}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [02:58, 17.82s/it]\n",
      "\u001b[32m[I 2021-11-03 17:57:32,266]\u001b[0m Trial 35 finished with value: 0.7458932030123769 and parameters: {'learning_rate': 0.11316468951535044, 'iterations': 9073, 'depth': 8, 'l2_leaf_reg': 58.50318080402997, 'bagging_temperature': 3.7967995025076373}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:47, 34.70s/it]\n",
      "\u001b[32m[I 2021-11-03 18:03:19,400]\u001b[0m Trial 36 finished with value: 0.7478952485784 and parameters: {'learning_rate': 0.05816064110010723, 'iterations': 9509, 'depth': 4, 'l2_leaf_reg': 66.30274994447979, 'bagging_temperature': 4.970639547244874}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [02:31, 15.17s/it]\n",
      "\u001b[32m[I 2021-11-03 18:05:51,207]\u001b[0m Trial 37 finished with value: 0.7469114141475137 and parameters: {'learning_rate': 0.13887774529020525, 'iterations': 9991, 'depth': 3, 'l2_leaf_reg': 32.188140397751276, 'bagging_temperature': 4.965707749010805}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:24, 26.42s/it]\n",
      "\u001b[32m[I 2021-11-03 18:10:15,551]\u001b[0m Trial 38 finished with value: 0.7473213204503726 and parameters: {'learning_rate': 0.1130542065197156, 'iterations': 9361, 'depth': 4, 'l2_leaf_reg': 64.83845576172625, 'bagging_temperature': 6.123793798887274}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:13, 37.35s/it]\n",
      "\u001b[32m[I 2021-11-03 18:16:29,150]\u001b[0m Trial 39 finished with value: 0.7480200618703362 and parameters: {'learning_rate': 0.05834352260761194, 'iterations': 8793, 'depth': 5, 'l2_leaf_reg': 51.45758378229774, 'bagging_temperature': 5.229383674656098}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:50, 41.08s/it]\n",
      "\u001b[32m[I 2021-11-03 18:23:20,033]\u001b[0m Trial 40 finished with value: 0.7480059631508602 and parameters: {'learning_rate': 0.030176790349185398, 'iterations': 8541, 'depth': 5, 'l2_leaf_reg': 38.794397560909594, 'bagging_temperature': 6.458592630756837}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:54, 41.45s/it]\n",
      "\u001b[32m[I 2021-11-03 18:30:14,610]\u001b[0m Trial 41 finished with value: 0.748143974582543 and parameters: {'learning_rate': 0.043256066982006375, 'iterations': 8634, 'depth': 5, 'l2_leaf_reg': 37.0231070560501, 'bagging_temperature': 6.453480403971978}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [07:01, 42.20s/it]\n",
      "\u001b[32m[I 2021-11-03 18:37:16,683]\u001b[0m Trial 42 finished with value: 0.7479857503822208 and parameters: {'learning_rate': 0.03364310130135804, 'iterations': 8762, 'depth': 5, 'l2_leaf_reg': 38.74664087067932, 'bagging_temperature': 6.629662856236263}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [02:38, 15.82s/it]\n",
      "\u001b[32m[I 2021-11-03 18:39:54,981]\u001b[0m Trial 43 finished with value: 0.7470891175898955 and parameters: {'learning_rate': 0.09075125789471242, 'iterations': 4643, 'depth': 3, 'l2_leaf_reg': 49.76423267412976, 'bagging_temperature': 5.978926859314753}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [02:40, 16.02s/it]\n",
      "\u001b[32m[I 2021-11-03 18:42:35,264]\u001b[0m Trial 44 finished with value: 0.7449833006955535 and parameters: {'learning_rate': 0.031826419455831645, 'iterations': 3182, 'depth': 5, 'l2_leaf_reg': 42.88844664202486, 'bagging_temperature': 7.29763210387817}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [01:06,  6.60s/it]\n",
      "\u001b[32m[I 2021-11-03 18:43:41,365]\u001b[0m Trial 45 finished with value: 0.7449973254816549 and parameters: {'learning_rate': 0.07468184435188246, 'iterations': 1465, 'depth': 4, 'l2_leaf_reg': 22.431435133641003, 'bagging_temperature': 6.510715246787833}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:09, 24.92s/it]\n",
      "\u001b[32m[I 2021-11-03 18:47:50,629]\u001b[0m Trial 46 finished with value: 0.7383081480300441 and parameters: {'learning_rate': 0.11822115652822304, 'iterations': 9598, 'depth': 11, 'l2_leaf_reg': 34.80398256616568, 'bagging_temperature': 5.482563100849768}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [02:44, 16.50s/it]\n",
      "\u001b[32m[I 2021-11-03 18:50:35,696]\u001b[0m Trial 47 finished with value: 0.7446416914518692 and parameters: {'learning_rate': 0.16803615285297416, 'iterations': 7205, 'depth': 6, 'l2_leaf_reg': 54.82519076123914, 'bagging_temperature': 7.392734755958218}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:36, 39.63s/it]\n",
      "\u001b[32m[I 2021-11-03 18:57:12,055]\u001b[0m Trial 48 finished with value: 0.7480640481073456 and parameters: {'learning_rate': 0.05052675989547503, 'iterations': 8373, 'depth': 5, 'l2_leaf_reg': 10.566754093284857, 'bagging_temperature': 6.408873735382845}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:23, 26.37s/it]\n",
      "\u001b[32m[I 2021-11-03 19:01:35,864]\u001b[0m Trial 49 finished with value: 0.7472621381599276 and parameters: {'learning_rate': 0.09837957472331615, 'iterations': 7862, 'depth': 3, 'l2_leaf_reg': 5.851764529887411, 'bagging_temperature': 8.377432210065498}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [02:37, 15.72s/it]\n",
      "\u001b[32m[I 2021-11-03 19:04:13,164]\u001b[0m Trial 50 finished with value: 0.7460397970241547 and parameters: {'learning_rate': 0.13169610696032735, 'iterations': 9669, 'depth': 6, 'l2_leaf_reg': 17.761865548340197, 'bagging_temperature': 5.835645477093888}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:42, 40.23s/it]\n",
      "\u001b[32m[I 2021-11-03 19:10:55,564]\u001b[0m Trial 51 finished with value: 0.7480531267018161 and parameters: {'learning_rate': 0.04712809230117358, 'iterations': 8413, 'depth': 5, 'l2_leaf_reg': 14.00416733029833, 'bagging_temperature': 6.523914009656994}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:48, 40.87s/it]\n",
      "\u001b[32m[I 2021-11-03 19:17:44,399]\u001b[0m Trial 52 finished with value: 0.7480120619101496 and parameters: {'learning_rate': 0.048113621952192855, 'iterations': 8921, 'depth': 5, 'l2_leaf_reg': 0.3591784778613203, 'bagging_temperature': 5.241221001776836}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:22, 32.25s/it]\n",
      "\u001b[32m[I 2021-11-03 19:23:07,019]\u001b[0m Trial 53 finished with value: 0.7476367397699388 and parameters: {'learning_rate': 0.07719041861503459, 'iterations': 8356, 'depth': 4, 'l2_leaf_reg': 11.974927579662397, 'bagging_temperature': 6.933054791807522}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:44, 34.47s/it]\n",
      "\u001b[32m[I 2021-11-03 19:28:51,796]\u001b[0m Trial 54 finished with value: 0.7479982723002927 and parameters: {'learning_rate': 0.05064389633257833, 'iterations': 7549, 'depth': 5, 'l2_leaf_reg': 12.814563033393718, 'bagging_temperature': 4.444017756298542}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:41, 34.12s/it]\n",
      "\u001b[32m[I 2021-11-03 19:34:33,084]\u001b[0m Trial 55 finished with value: 0.746535232039778 and parameters: {'learning_rate': 0.08746992361119649, 'iterations': 7024, 'depth': 6, 'l2_leaf_reg': 27.347092770193505, 'bagging_temperature': 8.211995644737152}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [01:36,  9.60s/it]\n",
      "\u001b[32m[I 2021-11-03 19:36:09,202]\u001b[0m Trial 56 finished with value: 0.7442839798002818 and parameters: {'learning_rate': 0.31083720246834795, 'iterations': 8875, 'depth': 3, 'l2_leaf_reg': 5.265185320153492, 'bagging_temperature': 6.355863335022248}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [01:47, 10.77s/it]\n",
      "\u001b[32m[I 2021-11-03 19:37:56,963]\u001b[0m Trial 57 finished with value: 0.7455924498868034 and parameters: {'learning_rate': 0.22044763091280042, 'iterations': 9590, 'depth': 4, 'l2_leaf_reg': 15.975584315729842, 'bagging_temperature': 5.737159282537485}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [08:14, 49.40s/it]\n",
      "\u001b[32m[I 2021-11-03 19:46:11,106]\u001b[0m Trial 58 finished with value: 0.7477914309472661 and parameters: {'learning_rate': 0.047967140244548824, 'iterations': 8602, 'depth': 6, 'l2_leaf_reg': 24.481029305138424, 'bagging_temperature': 7.4993925073254}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:28, 38.90s/it]\n",
      "\u001b[32m[I 2021-11-03 19:52:40,183]\u001b[0m Trial 59 finished with value: 0.7475242745892204 and parameters: {'learning_rate': 0.07112922957871069, 'iterations': 7897, 'depth': 5, 'l2_leaf_reg': 54.37955806781301, 'bagging_temperature': 8.834115574259199}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [07:39, 45.99s/it]\n",
      "\u001b[32m[I 2021-11-03 20:00:20,216]\u001b[0m Trial 60 finished with value: 0.7107146397643012 and parameters: {'learning_rate': 0.4148863302226542, 'iterations': 2121, 'depth': 14, 'l2_leaf_reg': 22.538868596190195, 'bagging_temperature': 4.745038008784971}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:23, 38.35s/it]\n",
      "\u001b[32m[I 2021-11-03 20:06:43,812]\u001b[0m Trial 61 finished with value: 0.7479536562828986 and parameters: {'learning_rate': 0.04837123600386859, 'iterations': 8871, 'depth': 5, 'l2_leaf_reg': 1.1515135996271253, 'bagging_temperature': 5.304793729007359}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:31, 33.12s/it]\n",
      "\u001b[32m[I 2021-11-03 20:12:15,132]\u001b[0m Trial 62 finished with value: 0.7479142603183071 and parameters: {'learning_rate': 0.0469873504223688, 'iterations': 8358, 'depth': 4, 'l2_leaf_reg': 3.432786118698374, 'bagging_temperature': 5.276712948261608}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:09, 24.99s/it]\n",
      "\u001b[32m[I 2021-11-03 20:16:25,146]\u001b[0m Trial 63 finished with value: 0.7465797033489486 and parameters: {'learning_rate': 0.09656687744794448, 'iterations': 9163, 'depth': 6, 'l2_leaf_reg': 9.069055995464929, 'bagging_temperature': 6.79425030429857}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [01:10,  7.00s/it]\n",
      "\u001b[32m[I 2021-11-03 20:17:35,270]\u001b[0m Trial 64 finished with value: 0.7421876487997393 and parameters: {'learning_rate': 0.36804022169528106, 'iterations': 8912, 'depth': 5, 'l2_leaf_reg': 45.45932864205962, 'bagging_temperature': 6.23756125332365}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:35, 27.56s/it]\n",
      "\u001b[32m[I 2021-11-03 20:22:11,002]\u001b[0m Trial 65 finished with value: 0.7476207594004098 and parameters: {'learning_rate': 0.07905893790964441, 'iterations': 9703, 'depth': 4, 'l2_leaf_reg': 10.922194312791838, 'bagging_temperature': 4.110498582807544}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:06, 36.62s/it]\n",
      "\u001b[32m[I 2021-11-03 20:28:17,299]\u001b[0m Trial 66 finished with value: 0.747896904008646 and parameters: {'learning_rate': 0.06546657523248095, 'iterations': 9354, 'depth': 5, 'l2_leaf_reg': 14.462228227765303, 'bagging_temperature': 5.920904734685452}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [07:36, 45.66s/it]\n",
      "\u001b[32m[I 2021-11-03 20:35:53,967]\u001b[0m Trial 67 finished with value: 0.7453664151701714 and parameters: {'learning_rate': 0.049506293253477385, 'iterations': 8292, 'depth': 8, 'l2_leaf_reg': 0.5247340855067844, 'bagging_temperature': 7.191299230319187}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [03:42, 22.25s/it]\n",
      "\u001b[32m[I 2021-11-03 20:39:36,531]\u001b[0m Trial 68 finished with value: 0.7445481046190224 and parameters: {'learning_rate': 0.10513103929413013, 'iterations': 7878, 'depth': 7, 'l2_leaf_reg': 7.5396379359797745, 'bagging_temperature': 7.71537946412062}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [01:47, 10.79s/it]\n",
      "\u001b[32m[I 2021-11-03 20:41:24,484]\u001b[0m Trial 69 finished with value: 0.7433634885806906 and parameters: {'learning_rate': 0.25191300393683036, 'iterations': 7324, 'depth': 5, 'l2_leaf_reg': 20.281045692867302, 'bagging_temperature': 8.01869690158354}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:39, 27.97s/it]\n",
      "\u001b[32m[I 2021-11-03 20:46:04,262]\u001b[0m Trial 70 finished with value: 0.7472813506970359 and parameters: {'learning_rate': 0.042459923960652374, 'iterations': 9812, 'depth': 6, 'l2_leaf_reg': 28.9452162554336, 'bagging_temperature': 0.13350117100188275}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:51, 41.13s/it]\n",
      "\u001b[32m[I 2021-11-03 20:52:55,674]\u001b[0m Trial 71 finished with value: 0.7479591026695565 and parameters: {'learning_rate': 0.03217350691292787, 'iterations': 8569, 'depth': 5, 'l2_leaf_reg': 35.483053429359586, 'bagging_temperature': 6.540544526686616}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [07:00, 42.06s/it]\n",
      "\u001b[32m[I 2021-11-03 20:59:56,364]\u001b[0m Trial 72 finished with value: 0.7479771076444598 and parameters: {'learning_rate': 0.06363199332371533, 'iterations': 9259, 'depth': 5, 'l2_leaf_reg': 40.40985162794168, 'bagging_temperature': 6.995684843781618}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [08:03, 48.33s/it]\n",
      "\u001b[32m[I 2021-11-03 21:07:59,786]\u001b[0m Trial 73 finished with value: 0.7481613009449577 and parameters: {'learning_rate': 0.0429423562677623, 'iterations': 8479, 'depth': 6, 'l2_leaf_reg': 47.23412691621437, 'bagging_temperature': 6.392853693798422}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:13, 31.34s/it]\n",
      "\u001b[32m[I 2021-11-03 21:13:13,238]\u001b[0m Trial 74 finished with value: 0.7473370824736276 and parameters: {'learning_rate': 0.08323390570880607, 'iterations': 6507, 'depth': 6, 'l2_leaf_reg': 59.501168975234776, 'bagging_temperature': 5.580332056311807}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:54, 29.43s/it]\n",
      "\u001b[32m[I 2021-11-03 21:18:07,598]\u001b[0m Trial 75 finished with value: 0.7479045870788484 and parameters: {'learning_rate': 0.06048517133971638, 'iterations': 7712, 'depth': 4, 'l2_leaf_reg': 77.72200192816155, 'bagging_temperature': 5.169556806281639}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:59, 35.90s/it]\n",
      "\u001b[32m[I 2021-11-03 21:24:06,737]\u001b[0m Trial 76 finished with value: 0.748046733180636 and parameters: {'learning_rate': 0.04277114392510572, 'iterations': 8966, 'depth': 4, 'l2_leaf_reg': 45.016311466150356, 'bagging_temperature': 6.205278522856585}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [05:00, 30.08s/it]\n",
      "\u001b[32m[I 2021-11-03 21:29:07,676]\u001b[0m Trial 77 finished with value: 0.747668587050382 and parameters: {'learning_rate': 0.072309394917607, 'iterations': 9383, 'depth': 3, 'l2_leaf_reg': 44.48399714880106, 'bagging_temperature': 6.209718851226891}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [03:22, 20.22s/it]\n",
      "\u001b[32m[I 2021-11-03 21:32:29,966]\u001b[0m Trial 78 finished with value: 0.7464804813177147 and parameters: {'learning_rate': 0.03001688847315289, 'iterations': 4924, 'depth': 4, 'l2_leaf_reg': 51.62964252761357, 'bagging_temperature': 6.799419487756002}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [04:27, 26.76s/it]\n",
      "\u001b[32m[I 2021-11-03 21:36:57,702]\u001b[0m Trial 79 finished with value: 0.7475392371887828 and parameters: {'learning_rate': 0.08949243006919606, 'iterations': 8121, 'depth': 4, 'l2_leaf_reg': 47.839551890894775, 'bagging_temperature': 6.060169771463537}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [03:14, 19.42s/it]\n",
      "\u001b[32m[I 2021-11-03 21:40:12,000]\u001b[0m Trial 80 finished with value: 0.744199907823506 and parameters: {'learning_rate': 0.1269293210878418, 'iterations': 8599, 'depth': 7, 'l2_leaf_reg': 31.100630232283766, 'bagging_temperature': 7.522013928413795}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [06:21, 38.19s/it]\n",
      "\u001b[32m[I 2021-11-03 21:46:33,952]\u001b[0m Trial 81 finished with value: 0.7482387679180371 and parameters: {'learning_rate': 0.04663715377492989, 'iterations': 8454, 'depth': 5, 'l2_leaf_reg': 96.28984749848996, 'bagging_temperature': 4.697006861046505}. Best is trial 10 with value: 0.7482967771807189.\u001b[0m\n",
      "10it [08:31, 51.13s/it]\n",
      "\u001b[32m[I 2021-11-03 21:55:05,327]\u001b[0m Trial 82 finished with value: 0.7484177726266518 and parameters: {'learning_rate': 0.04162538299243625, 'iterations': 9096, 'depth': 6, 'l2_leaf_reg': 94.34314613260452, 'bagging_temperature': 4.840804981084371}. Best is trial 82 with value: 0.7484177726266518.\u001b[0m\n",
      "10it [08:26, 50.66s/it]\n",
      "\u001b[32m[I 2021-11-03 22:03:32,085]\u001b[0m Trial 83 finished with value: 0.7484675446541528 and parameters: {'learning_rate': 0.037036206635072906, 'iterations': 9012, 'depth': 6, 'l2_leaf_reg': 97.0255283241598, 'bagging_temperature': 4.6610162819132785}. Best is trial 83 with value: 0.7484675446541528.\u001b[0m\n",
      "10it [07:49, 46.92s/it]\n",
      "\u001b[32m[I 2021-11-03 22:11:21,348]\u001b[0m Trial 84 finished with value: 0.7483257077097589 and parameters: {'learning_rate': 0.03977048163873248, 'iterations': 8325, 'depth': 6, 'l2_leaf_reg': 95.4825079647987, 'bagging_temperature': 4.823017146448274}. Best is trial 83 with value: 0.7484675446541528.\u001b[0m\n",
      "10it [05:59, 35.93s/it]\n",
      "\u001b[32m[I 2021-11-03 22:17:20,717]\u001b[0m Trial 85 finished with value: 0.7474107312226952 and parameters: {'learning_rate': 0.07030046112846089, 'iterations': 5944, 'depth': 7, 'l2_leaf_reg': 96.28295833421387, 'bagging_temperature': 3.44963022641731}. Best is trial 83 with value: 0.7484675446541528.\u001b[0m\n",
      "10it [08:52, 53.26s/it]\n",
      "\u001b[32m[I 2021-11-03 22:26:13,411]\u001b[0m Trial 86 finished with value: 0.7482386155525036 and parameters: {'learning_rate': 0.03975987443685663, 'iterations': 9776, 'depth': 6, 'l2_leaf_reg': 89.74855373462415, 'bagging_temperature': 4.790455696796233}. Best is trial 83 with value: 0.7484675446541528.\u001b[0m\n",
      "10it [09:00, 54.04s/it]\n",
      "\u001b[32m[I 2021-11-03 22:35:13,962]\u001b[0m Trial 87 finished with value: 0.7482374217449622 and parameters: {'learning_rate': 0.04141683937909896, 'iterations': 9822, 'depth': 6, 'l2_leaf_reg': 85.3042552626704, 'bagging_temperature': 4.773284198854502}. Best is trial 83 with value: 0.7484675446541528.\u001b[0m\n",
      "10it [08:51, 53.20s/it]\n",
      "\u001b[32m[I 2021-11-03 22:44:06,067]\u001b[0m Trial 88 finished with value: 0.7484300135775619 and parameters: {'learning_rate': 0.038376213144151614, 'iterations': 9760, 'depth': 6, 'l2_leaf_reg': 85.63974575498719, 'bagging_temperature': 4.670037319316791}. Best is trial 83 with value: 0.7484675446541528.\u001b[0m\n",
      "10it [03:41, 22.11s/it]\n",
      "\u001b[32m[I 2021-11-03 22:47:47,278]\u001b[0m Trial 89 finished with value: 0.7460479234033007 and parameters: {'learning_rate': 0.10523346787230967, 'iterations': 9807, 'depth': 8, 'l2_leaf_reg': 84.25600692482644, 'bagging_temperature': 4.670902078098897}. Best is trial 83 with value: 0.7484675446541528.\u001b[0m\n",
      "10it [10:33, 63.36s/it]\n",
      "\u001b[32m[I 2021-11-03 22:58:20,971]\u001b[0m Trial 90 finished with value: 0.748542910949018 and parameters: {'learning_rate': 0.03050548949781178, 'iterations': 9529, 'depth': 7, 'l2_leaf_reg': 89.90684718615579, 'bagging_temperature': 4.271106622347548}. Best is trial 90 with value: 0.748542910949018.\u001b[0m\n",
      "10it [07:15, 43.54s/it]\n",
      "\u001b[32m[I 2021-11-03 23:05:36,502]\u001b[0m Trial 91 finished with value: 0.7481571214273209 and parameters: {'learning_rate': 0.058053933911440606, 'iterations': 9487, 'depth': 6, 'l2_leaf_reg': 90.17864759933522, 'bagging_temperature': 4.262996210966205}. Best is trial 90 with value: 0.748542910949018.\u001b[0m\n",
      "10it [09:17, 55.71s/it]\n",
      "\u001b[32m[I 2021-11-03 23:14:53,721]\u001b[0m Trial 92 finished with value: 0.7484279390685369 and parameters: {'learning_rate': 0.03927295298928736, 'iterations': 9986, 'depth': 6, 'l2_leaf_reg': 94.04159535678687, 'bagging_temperature': 4.837391239394419}. Best is trial 90 with value: 0.748542910949018.\u001b[0m\n",
      "10it [10:46, 64.65s/it]\n",
      "\u001b[32m[I 2021-11-03 23:25:40,282]\u001b[0m Trial 93 finished with value: 0.7484810459491859 and parameters: {'learning_rate': 0.03618545371674302, 'iterations': 9867, 'depth': 7, 'l2_leaf_reg': 93.4734001794768, 'bagging_temperature': 4.44246395104232}. Best is trial 90 with value: 0.748542910949018.\u001b[0m\n",
      "10it [11:06, 66.65s/it]\n",
      "\u001b[32m[I 2021-11-03 23:36:46,904]\u001b[0m Trial 94 finished with value: 0.7486246657153751 and parameters: {'learning_rate': 0.030553406554768365, 'iterations': 9945, 'depth': 7, 'l2_leaf_reg': 93.40061034371905, 'bagging_temperature': 4.462535963804907}. Best is trial 94 with value: 0.7486246657153751.\u001b[0m\n",
      "10it [11:10, 67.02s/it]\n",
      "\u001b[32m[I 2021-11-03 23:47:57,251]\u001b[0m Trial 95 finished with value: 0.7485702541127226 and parameters: {'learning_rate': 0.0316139299078642, 'iterations': 9988, 'depth': 7, 'l2_leaf_reg': 94.13185988355308, 'bagging_temperature': 4.381446124447253}. Best is trial 94 with value: 0.7486246657153751.\u001b[0m\n",
      "10it [13:27, 80.79s/it]\n",
      "\u001b[32m[I 2021-11-04 00:01:25,230]\u001b[0m Trial 96 finished with value: 0.7483347864976713 and parameters: {'learning_rate': 0.031235331296141394, 'iterations': 9923, 'depth': 8, 'l2_leaf_reg': 93.88595588630507, 'bagging_temperature': 4.39404893162026}. Best is trial 94 with value: 0.7486246657153751.\u001b[0m\n",
      "10it [08:08, 48.86s/it]\n",
      "\u001b[32m[I 2021-11-04 00:09:33,938]\u001b[0m Trial 97 finished with value: 0.7467002165570766 and parameters: {'learning_rate': 0.05839494296278458, 'iterations': 9968, 'depth': 9, 'l2_leaf_reg': 92.77493335675112, 'bagging_temperature': 4.4235945429696315}. Best is trial 94 with value: 0.7486246657153751.\u001b[0m\n",
      "10it [10:41, 64.16s/it]\n",
      "\u001b[32m[I 2021-11-04 00:20:15,635]\u001b[0m Trial 98 finished with value: 0.7486647440823471 and parameters: {'learning_rate': 0.031190673582301456, 'iterations': 9560, 'depth': 7, 'l2_leaf_reg': 98.16696275126748, 'bagging_temperature': 4.021848378181608}. Best is trial 98 with value: 0.7486647440823471.\u001b[0m\n",
      "10it [12:33, 75.31s/it]\n",
      "\u001b[32m[I 2021-11-04 00:32:48,868]\u001b[0m Trial 99 finished with value: 0.7484232262775201 and parameters: {'learning_rate': 0.0306492495999773, 'iterations': 9568, 'depth': 8, 'l2_leaf_reg': 80.70621651252327, 'bagging_temperature': 3.5657998723667363}. Best is trial 98 with value: 0.7486647440823471.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FrozenTrial(number=98, values=[0.7486647440823471], datetime_start=datetime.datetime(2021, 11, 4, 0, 9, 33, 942015), datetime_complete=datetime.datetime(2021, 11, 4, 0, 20, 15, 610064), params={'bagging_temperature': 4.021848378181608, 'depth': 7, 'iterations': 9560, 'l2_leaf_reg': 98.16696275126748, 'learning_rate': 0.031190673582301456}, distributions={'bagging_temperature': UniformDistribution(high=10.0, low=0.0), 'depth': IntUniformDistribution(high=15, low=3, step=1), 'iterations': IntUniformDistribution(high=10000, low=500, step=1), 'l2_leaf_reg': UniformDistribution(high=100.0, low=0.01), 'learning_rate': UniformDistribution(high=0.5, low=0.03)}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=99, state=TrialState.COMPLETE, value=None)\n"
     ]
    }
   ],
   "source": [
    "study.optimize(lambda trial: objective(trial, X, y, \"catboost\"),  n_trials=100)\n",
    "print(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9628d22-f7eb-4768-8195-dbae18734b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-11-04 00:32:48.886629\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfccda96-cde2-4ee2-941e-2bf6211a4e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
